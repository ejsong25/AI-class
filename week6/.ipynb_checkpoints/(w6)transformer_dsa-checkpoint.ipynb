{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eabc5b5-e756-48b2-bdae-7180a9b815c5",
   "metadata": {},
   "source": [
    "# Week6\n",
    "Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40ad8215-db20-40c3-bc0a-d676b4b12e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd888e2b-68c9-49e1-88c4-113b159dd28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "      <th>activity</th>\n",
       "      <th>people</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.975714</td>\n",
       "      <td>8.1605</td>\n",
       "      <td>7.6823</td>\n",
       "      <td>0.014395</td>\n",
       "      <td>0.119981</td>\n",
       "      <td>-0.023319</td>\n",
       "      <td>1.083150</td>\n",
       "      <td>1.1832</td>\n",
       "      <td>0.99744</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.177075</td>\n",
       "      <td>-0.057119</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.059241</td>\n",
       "      <td>6.778722e-07</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.036729</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.978250</td>\n",
       "      <td>8.1763</td>\n",
       "      <td>7.8472</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>0.086896</td>\n",
       "      <td>0.552416</td>\n",
       "      <td>1.140865</td>\n",
       "      <td>1.2129</td>\n",
       "      <td>1.05810</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>-0.286918</td>\n",
       "      <td>-0.057268</td>\n",
       "      <td>-0.054945</td>\n",
       "      <td>-0.059589</td>\n",
       "      <td>7.032302e-07</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.347471</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.970894</td>\n",
       "      <td>8.0860</td>\n",
       "      <td>7.8470</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.055603</td>\n",
       "      <td>0.100538</td>\n",
       "      <td>1.140962</td>\n",
       "      <td>1.2128</td>\n",
       "      <td>1.07960</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>-0.134430</td>\n",
       "      <td>-0.057068</td>\n",
       "      <td>-0.054711</td>\n",
       "      <td>-0.059065</td>\n",
       "      <td>6.268222e-07</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.045579</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.938412</td>\n",
       "      <td>8.1083</td>\n",
       "      <td>7.6901</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.061343</td>\n",
       "      <td>-0.231914</td>\n",
       "      <td>1.165260</td>\n",
       "      <td>1.3170</td>\n",
       "      <td>1.07870</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.021485</td>\n",
       "      <td>-0.056422</td>\n",
       "      <td>-0.053670</td>\n",
       "      <td>-0.058310</td>\n",
       "      <td>8.011245e-07</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.240690</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.908930</td>\n",
       "      <td>8.1305</td>\n",
       "      <td>7.8322</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.041731</td>\n",
       "      <td>2.042285</td>\n",
       "      <td>1.187504</td>\n",
       "      <td>1.2574</td>\n",
       "      <td>1.09450</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>-0.148229</td>\n",
       "      <td>-0.055801</td>\n",
       "      <td>-0.053313</td>\n",
       "      <td>-0.057815</td>\n",
       "      <td>6.853423e-07</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.258429</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  T_xacc_skew  \\\n",
       "0     7.975714      8.1605      7.6823    0.014395    0.119981    -0.023319   \n",
       "1     7.978250      8.1763      7.8472    0.007551    0.086896     0.552416   \n",
       "2     7.970894      8.0860      7.8470    0.003092    0.055603     0.100538   \n",
       "3     7.938412      8.1083      7.6901    0.003763    0.061343    -0.231914   \n",
       "4     7.908930      8.1305      7.8322    0.001741    0.041731     2.042285   \n",
       "\n",
       "   T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  LL_ymag_std  \\\n",
       "0     1.083150      1.1832     0.99744    0.002208  ...     0.000792   \n",
       "1     1.140865      1.2129     1.05810    0.000784  ...     0.000860   \n",
       "2     1.140962      1.2128     1.07960    0.000508  ...     0.000762   \n",
       "3     1.165260      1.3170     1.07870    0.002173  ...     0.000735   \n",
       "4     1.187504      1.2574     1.09450    0.000662  ...     0.000824   \n",
       "\n",
       "   LL_ymag_skew  LL_zmag_mean  LL_zmag_max  LL_zmag_min   LL_zmag_var  \\\n",
       "0      0.177075     -0.057119    -0.054963    -0.059241  6.778722e-07   \n",
       "1     -0.286918     -0.057268    -0.054945    -0.059589  7.032302e-07   \n",
       "2     -0.134430     -0.057068    -0.054711    -0.059065  6.268222e-07   \n",
       "3      0.021485     -0.056422    -0.053670    -0.058310  8.011245e-07   \n",
       "4     -0.148229     -0.055801    -0.053313    -0.057815  6.853423e-07   \n",
       "\n",
       "   LL_zmag_std  LL_zmag_skew  activity  people  \n",
       "0     0.000823      0.036729   sitting      p1  \n",
       "1     0.000839      0.347471   sitting      p1  \n",
       "2     0.000792      0.045579   sitting      p1  \n",
       "3     0.000895      0.240690   sitting      p1  \n",
       "4     0.000828      0.258429   sitting      p1  \n",
       "\n",
       "[5 rows x 272 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../dataset/DSA_features.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ba20604-d83e-4504-b441-d21082ab3228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activity\n",
       "lyingBack    480\n",
       "lyingRigh    480\n",
       "jumping      480\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 관심있는 3가지 activity 추출\n",
    "df = df.loc[df['activity'].isin(['lyingRigh', 'lyingBack', 'jumping'])]\n",
    "df['activity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1229186-db0a-4163-989b-35b717eb651c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((480, 272), (960, 272))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abnormal = df[df.activity == 'jumping']\n",
    "normal = df[df.activity.isin(['lyingRigh', 'lyingBack'])]\n",
    "\n",
    "abnormal.shape, normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df6eeb16-a5c8-459f-9713-1b5c280845be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['T_xacc_mean', 'T_xacc_max', 'T_xacc_min', 'T_xacc_var', 'T_xacc_std',\n",
       "       'T_xacc_skew', 'T_yacc_mean', 'T_yacc_max', 'T_yacc_min', 'T_yacc_var',\n",
       "       ...\n",
       "       'LL_ymag_skew', 'LL_zmag_mean', 'LL_zmag_max', 'LL_zmag_min',\n",
       "       'LL_zmag_var', 'LL_zmag_std', 'LL_zmag_skew', 'activity', 'people',\n",
       "       'class'],\n",
       "      dtype='object', length=273)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'] = df['activity'].apply(lambda x: 'normal' if x.startswith('lying') else 'abnormal')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dc85d1b-3527-495d-88f9-f9d0cf69ddc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_var</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>-4.834646</td>\n",
       "      <td>-4.7185</td>\n",
       "      <td>-4.9049</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.033529</td>\n",
       "      <td>0.632141</td>\n",
       "      <td>-0.501018</td>\n",
       "      <td>-0.41744</td>\n",
       "      <td>-0.59561</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>...</td>\n",
       "      <td>9.725263e-07</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.074676</td>\n",
       "      <td>-0.532664</td>\n",
       "      <td>-0.52993</td>\n",
       "      <td>-0.53521</td>\n",
       "      <td>9.585668e-07</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>-0.193301</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>-4.780810</td>\n",
       "      <td>-4.5850</td>\n",
       "      <td>-4.8833</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>0.062835</td>\n",
       "      <td>1.052880</td>\n",
       "      <td>-0.480601</td>\n",
       "      <td>-0.40372</td>\n",
       "      <td>-0.63184</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>...</td>\n",
       "      <td>6.211659e-07</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>-0.181526</td>\n",
       "      <td>-0.531169</td>\n",
       "      <td>-0.52940</td>\n",
       "      <td>-0.53365</td>\n",
       "      <td>7.608973e-07</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>-0.372381</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>-4.804400</td>\n",
       "      <td>-4.7037</td>\n",
       "      <td>-4.8755</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.038496</td>\n",
       "      <td>0.735226</td>\n",
       "      <td>-0.493925</td>\n",
       "      <td>-0.42616</td>\n",
       "      <td>-0.59561</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>...</td>\n",
       "      <td>4.579046e-07</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>-0.263115</td>\n",
       "      <td>-0.530569</td>\n",
       "      <td>-0.52873</td>\n",
       "      <td>-0.53222</td>\n",
       "      <td>5.160537e-07</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.185587</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>-4.750563</td>\n",
       "      <td>-4.5696</td>\n",
       "      <td>-4.8977</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.066683</td>\n",
       "      <td>0.710263</td>\n",
       "      <td>-0.437358</td>\n",
       "      <td>-0.30877</td>\n",
       "      <td>-0.55225</td>\n",
       "      <td>0.003587</td>\n",
       "      <td>...</td>\n",
       "      <td>4.703523e-07</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>-0.060925</td>\n",
       "      <td>-0.531167</td>\n",
       "      <td>-0.52962</td>\n",
       "      <td>-0.53283</td>\n",
       "      <td>4.975523e-07</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>-0.145321</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>-4.774916</td>\n",
       "      <td>-4.6741</td>\n",
       "      <td>-4.8457</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.032868</td>\n",
       "      <td>0.324779</td>\n",
       "      <td>-0.459456</td>\n",
       "      <td>-0.38900</td>\n",
       "      <td>-0.53714</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>...</td>\n",
       "      <td>5.467316e-07</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.335811</td>\n",
       "      <td>-0.529804</td>\n",
       "      <td>-0.52706</td>\n",
       "      <td>-0.53251</td>\n",
       "      <td>1.292131e-06</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>-0.026271</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 271 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  T_xacc_skew  \\\n",
       "960    -4.834646     -4.7185     -4.9049    0.001124    0.033529     0.632141   \n",
       "961    -4.780810     -4.5850     -4.8833    0.003948    0.062835     1.052880   \n",
       "962    -4.804400     -4.7037     -4.8755    0.001482    0.038496     0.735226   \n",
       "963    -4.750563     -4.5696     -4.8977    0.004447    0.066683     0.710263   \n",
       "964    -4.774916     -4.6741     -4.8457    0.001080    0.032868     0.324779   \n",
       "\n",
       "     T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...   LL_ymag_var  \\\n",
       "960    -0.501018    -0.41744    -0.59561    0.001016  ...  9.725263e-07   \n",
       "961    -0.480601    -0.40372    -0.63184    0.001297  ...  6.211659e-07   \n",
       "962    -0.493925    -0.42616    -0.59561    0.000863  ...  4.579046e-07   \n",
       "963    -0.437358    -0.30877    -0.55225    0.003587  ...  4.703523e-07   \n",
       "964    -0.459456    -0.38900    -0.53714    0.001059  ...  5.467316e-07   \n",
       "\n",
       "     LL_ymag_std  LL_ymag_skew  LL_zmag_mean  LL_zmag_max  LL_zmag_min  \\\n",
       "960     0.000986      0.074676     -0.532664     -0.52993     -0.53521   \n",
       "961     0.000788     -0.181526     -0.531169     -0.52940     -0.53365   \n",
       "962     0.000677     -0.263115     -0.530569     -0.52873     -0.53222   \n",
       "963     0.000686     -0.060925     -0.531167     -0.52962     -0.53283   \n",
       "964     0.000739      0.335811     -0.529804     -0.52706     -0.53251   \n",
       "\n",
       "      LL_zmag_var  LL_zmag_std  LL_zmag_skew   class  \n",
       "960  9.585668e-07     0.000979     -0.193301  normal  \n",
       "961  7.608973e-07     0.000872     -0.372381  normal  \n",
       "962  5.160537e-07     0.000718      0.185587  normal  \n",
       "963  4.975523e-07     0.000705     -0.145321  normal  \n",
       "964  1.292131e-06     0.001137     -0.026271  normal  \n",
       "\n",
       "[5 rows x 271 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.drop(['activity', 'people'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d6257a-486f-4065-8e63-61ce649039a9",
   "metadata": {},
   "source": [
    "#### Train, Test data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e98ab63c-d57b-4a7b-ba52-6510ffeb867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "# normal Train data\n",
    "X_train = normal.drop(['activity', 'people'], axis=1)\n",
    "\n",
    "# mixed test data\n",
    "X_mix = df.iloc[:, :-1].drop(['activity', 'people'], axis=1).values\n",
    "y_mix = df.iloc[:, -1].values\n",
    "y_mix = le.fit_transform(y_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc57273b-9eb4-44ef-9cb6-375a0fd88d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_mix = ss.transform(X_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba62a1be-fe8b-402e-acb4-99720f170dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mix_train, X_min_test, y_mix_train, y_mix_test = train_test_split(\n",
    "    X_mix, y_mix, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba8f9d60-6d10-4f33-8179-1ebfdc37ecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "X_train = X_mix_train.reshape((X_mix_train.shape[0], X_mix_train.shape[1], 1))\n",
    "X_test = X_min_test.reshape((X_min_test.shape[0], X_min_test.shape[1], 1))\n",
    "\n",
    "n_classes = len(np.unique(y_mix_train)) # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42cd9128-cf0c-40fe-b7f9-97f6e9322fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1152, 270, 1), (1152,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_mix_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a0a9ce4-e125-4c84-b2f1-23a4aa851059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((288, 270, 1), (288,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_mix_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23357a52-7388-4a54-be3c-5210705e5953",
   "metadata": {},
   "source": [
    "#### Construct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "68548fec-bdbb-4418-86bb-97ab5d9e7c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "bd2d5244-aa83-431b-9ec4-3cd31833e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    \n",
    "    # Attention and Normalization\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(inputs, inputs)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(res)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "4ffae7c3-37a5-424f-b7ca-92980a68a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape,\n",
    "                head_size,\n",
    "                num_heads,\n",
    "                ff_dim,\n",
    "                num_transformer_blocks,\n",
    "                mlp_units,\n",
    "                dropout=0,\n",
    "                mlp_dropout=0,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    \n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_last\")(x)\n",
    "    \n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    \n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7129ae9e-4bbc-4c22-92e8-f71b5db18bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_17       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                           │                 │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_29        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ dropout_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ add_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ dropout_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_30        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ conv1d_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ add_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_18       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> │ add_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], add_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_31        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ dropout_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ add_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ add_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ dropout_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_32        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ conv1d_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ add_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_19       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> │ add_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], add_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_33        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ dropout_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ add_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ add_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ dropout_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_34        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ conv1d_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ add_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_20       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> │ add_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], add_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_35        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ dropout_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ add_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ add_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ dropout_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_36        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ conv1d_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ add_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_3    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ global_average_pooling1d_… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_17       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │           \u001b[38;5;34m7,169\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                           │                 │ input_layer_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_50 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_head_attention_17[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_29        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m2\u001b[0m │ dropout_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_29 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_29[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ input_layer_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_29 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)            │               \u001b[38;5;34m8\u001b[0m │ add_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_51 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ conv1d_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_30 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m5\u001b[0m │ dropout_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_30        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m2\u001b[0m │ conv1d_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_30 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_30[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ add_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_18       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │           \u001b[38;5;34m7,169\u001b[0m │ add_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], add_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_53 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_head_attention_18[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_31        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m2\u001b[0m │ dropout_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_31 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_31[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ add_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_31 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)            │               \u001b[38;5;34m8\u001b[0m │ add_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_54 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ conv1d_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_32 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m5\u001b[0m │ dropout_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_32        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m2\u001b[0m │ conv1d_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_32 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_32[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ add_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_19       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │           \u001b[38;5;34m7,169\u001b[0m │ add_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], add_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_56 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_head_attention_19[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_33        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m2\u001b[0m │ dropout_56[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_33 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_33[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ add_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_33 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)            │               \u001b[38;5;34m8\u001b[0m │ add_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_57 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ conv1d_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_34 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m5\u001b[0m │ dropout_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_34        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m2\u001b[0m │ conv1d_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_34 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_34[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ add_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_20       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │           \u001b[38;5;34m7,169\u001b[0m │ add_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], add_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_59 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_head_attention_20[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_35        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m2\u001b[0m │ dropout_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_35 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_35[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ add_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_35 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)            │               \u001b[38;5;34m8\u001b[0m │ add_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_60 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ conv1d_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_36 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m5\u001b[0m │ dropout_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_36        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m2\u001b[0m │ conv1d_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_36 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_36[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ add_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_3    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ add_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m256\u001b[0m │ global_average_pooling1d_… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_61 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │             \u001b[38;5;34m129\u001b[0m │ dropout_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,129</span> (113.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,129\u001b[0m (113.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,129</span> (113.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,129\u001b[0m (113.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 6s/step - accuracy: 0.5125 - loss: 0.6926 - val_accuracy: 0.6562 - val_loss: 0.6916\n",
      "Epoch 2/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 5s/step - accuracy: 0.6355 - loss: 0.6908 - val_accuracy: 0.6562 - val_loss: 0.6901\n",
      "Epoch 3/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 6s/step - accuracy: 0.6679 - loss: 0.6900 - val_accuracy: 0.6562 - val_loss: 0.6885\n",
      "Epoch 4/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 5s/step - accuracy: 0.6762 - loss: 0.6884 - val_accuracy: 0.6562 - val_loss: 0.6869\n",
      "Epoch 5/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 8s/step - accuracy: 0.6600 - loss: 0.6868 - val_accuracy: 0.6562 - val_loss: 0.6853\n",
      "Epoch 6/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 6s/step - accuracy: 0.7006 - loss: 0.6834 - val_accuracy: 0.6562 - val_loss: 0.6835\n",
      "Epoch 7/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 6s/step - accuracy: 0.6833 - loss: 0.6826 - val_accuracy: 0.6562 - val_loss: 0.6818\n",
      "Epoch 8/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 5s/step - accuracy: 0.6649 - loss: 0.6804 - val_accuracy: 0.6562 - val_loss: 0.6801\n",
      "Epoch 9/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 5s/step - accuracy: 0.6838 - loss: 0.6783 - val_accuracy: 0.6562 - val_loss: 0.6784\n",
      "Epoch 10/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 5s/step - accuracy: 0.6691 - loss: 0.6779 - val_accuracy: 0.6562 - val_loss: 0.6766\n",
      "Epoch 11/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 5s/step - accuracy: 0.6933 - loss: 0.6733 - val_accuracy: 0.6562 - val_loss: 0.6748\n",
      "Epoch 12/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 5s/step - accuracy: 0.6830 - loss: 0.6709 - val_accuracy: 0.6562 - val_loss: 0.6730\n",
      "Epoch 13/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 5s/step - accuracy: 0.6939 - loss: 0.6683 - val_accuracy: 0.6562 - val_loss: 0.6711\n",
      "Epoch 14/150\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m11s\u001b[0m 6s/step - accuracy: 0.6440 - loss: 0.6728"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[175], line 25\u001b[0m\n\u001b[0;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m     23\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)]\n\u001b[1;32m---> 25\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     26\u001b[0m     X_train,\n\u001b[0;32m     27\u001b[0m     y_mix_train,\n\u001b[0;32m     28\u001b[0m     validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[0;32m     29\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m,\n\u001b[0;32m     30\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[0;32m     31\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     34\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(X_mix_test, y_mix_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:318\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    317\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 318\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    319\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    320\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1553\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1554\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1555\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1556\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1557\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1558\u001b[0m   )\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1567\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_shape = X_mix_train.shape[1:]\n",
    "\n",
    "# X_train = np.expand_dims(X_mix_train, axis=-1)  # (1000, 270, 1)로 변환\n",
    "\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=256,\n",
    "    num_heads=4,\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.25,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_mix_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=150,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "model.evaluate(X_mix_test, y_mix_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc3cd36-101b-4dc8-af34-9bfd5ea9423b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758aecc5-19f1-4c52-91d3-364bf48650b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd374358-c8a4-4ea8-9670-9222665bda05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
